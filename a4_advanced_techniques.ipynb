{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c139f9e1",
   "metadata": {},
   "source": [
    "<h2><center> MACHINE LEARNING PROJECT - N. 6 </center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56e580",
   "metadata": {},
   "source": [
    "<h3><center> Subscript nr. 4 - Advanced Techniques </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe5254",
   "metadata": {},
   "source": [
    "This notebook contains some alternative models proposed by us to complete the analysis.\n",
    "\n",
    "Some of the libraries used are <i>sklearn</i> and <i>imblearn</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41015165",
   "metadata": {},
   "source": [
    "### Random over sampling Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff622046",
   "metadata": {},
   "source": [
    "A decision tree has been performed on the balanced data by using the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff44aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ros_tree(new_df, ros_df, clf, dict_font):\n",
    "   \n",
    "    X_train_ros, _, y_train_ros, _ = train_test_split(\n",
    "                        ros_df[[\"Latitude\", \"TempCels\", \"SpecHum\", \"RelHum\", \"AbsHum\"]],\n",
    "                        ros_df[\"Cases\"], test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "                        new_df[[\"Latitude\", \"TempCels\", \"SpecHum\", \"RelHum\", \"AbsHum\"]],\n",
    "                        new_df[\"Cases\"], test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    clf = clf.fit(X_train_ros, y_train_ros)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"Test MSE: \", round( metrics.mean_squared_error(y_test, y_pred) , 3))\n",
    "    print(\"Test MAPE: \", round( metrics.mean_absolute_percentage_error(y_test, y_pred) , 3))\n",
    "    print(\"Test MAE: \", round( metrics.median_absolute_error(y_test, y_pred) , 3))\n",
    "    #print(\"The median is more robust to outliers. The percentage error is high.\")\n",
    "    \n",
    "    fig = plt.figure(figsize = np.array(dict_font[\"fig_size\"]) * [2, 2])\n",
    "    plt.rcParams['figure.dpi'] = dict_font[\"fig_dpi\"] * 2\n",
    "    t = tree.plot_tree(clf, filled = True, feature_names = X_train_ros.columns.to_list(),\n",
    "    rounded = True, proportion = False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec8f68",
   "metadata": {},
   "source": [
    "### Random over sampling regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f4347",
   "metadata": {},
   "source": [
    "A linear regression has been used to understand if the covid cases (from random oversampling dataset) are linearly related to the other variables. \n",
    "The function performs the summary of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575aa49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ros_reg(new_df, ros_df):\n",
    "    \n",
    "    X_train_ros, _, y_train_ros, _ = train_test_split(\n",
    "                    ros_df[[\"Latitude\", \"TempCels\", \"SpecHum\", \"RelHum\", \"AbsHum\"]], \n",
    "                    ros_df[\"Cases\"], test_size = 0.2, random_state = 1) \n",
    "    \n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "                    new_df[[\"Latitude\", \"TempCels\", \"SpecHum\", \"RelHum\", \"AbsHum\"]], \n",
    "                    new_df[\"Cases\"], test_size = 0.2, random_state = 1) \n",
    "\n",
    "    # X_train_ros_2 = sm.add_constant(X_train_ros) # column of ones to estimate intercept\n",
    "    X_train_ros_2 = X_train_ros.copy()\n",
    "    X_train_ros_2[\"Const\"] = 1 # add_constant may be not well-suited for pd.dataframes\n",
    "    model2 = sm.OLS(y_train_ros, X_train_ros_2).fit()\n",
    "    print(model2.summary())\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_ros, y_train_ros)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('MAE:', round(metrics.mean_absolute_error(y_test, y_pred), 3) )\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028c1f9",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a206e5",
   "metadata": {},
   "source": [
    "#### Elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409253c",
   "metadata": {},
   "source": [
    "The same is made with another kind of rule, the elbow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d10e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_elbow(scaled_df, dict_font):\n",
    "    elbow_scores = {}\n",
    "    K = range(1, 25) # 1 clusters is meaningless\n",
    "    \n",
    "    for k in K:\n",
    "        model_kmeans_k = KMeans(n_clusters = k)\n",
    "        model_kmeans_k.fit(scaled_df)\n",
    "        labels_k = model_kmeans_k.labels_  \n",
    "        elbow_scores[k] = model_kmeans_k.inertia_\n",
    "\n",
    "    plt.figure(figsize = dict_font[\"fig_size\"])\n",
    "    plt.plot(K, elbow_scores.values(), marker = \"x\", markersize = dict_font[\"font_txt\"] * 0.5)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Elbow score')\n",
    "    plt.title('The Elbow Method')\n",
    "    plt.xticks(K)\n",
    "    plt.plot(3, elbow_scores[3], \"oy\", markersize = dict_font[\"font_xy\"] * 0.8, label = \"Solution A\", alpha = 0.75)\n",
    "    plt.plot(4, elbow_scores[4], \"og\", markersize = dict_font[\"font_xy\"] * 0.8, label = \"Solution B\", alpha = 0.75)\n",
    "    plt.legend(title = 'Nr. Cluster', loc='best', fontsize = dict_font[\"font_txt\"] * 0.8)\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6e210",
   "metadata": {},
   "source": [
    "#### Silhouette plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8ea7e",
   "metadata": {},
   "source": [
    "A function to perform the choice on the number of clusters k is implemented. Furthermore the graph to plot the best k is presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3528bc",
   "metadata": {},
   "source": [
    "$$ \\frac{b - a}{\\max(a,b)} $$\n",
    "\n",
    "* a: mean intra-cluster distance\n",
    "* b: mean nearest- cluster distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed74255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_silhouette(scaled_df, dict_font):\n",
    "    k_to_test = range(2, 25) \n",
    "    silhouette_scores = {}\n",
    "\n",
    "    for k in k_to_test:\n",
    "        model_kmeans_k = KMeans(n_clusters = k)\n",
    "        model_kmeans_k.fit(scaled_df)\n",
    "        labels_k = model_kmeans_k.labels_\n",
    "        silhouette_scores[k] = metrics.silhouette_score(scaled_df, labels_k) # mean over whole samples\n",
    "\n",
    "    plt.rcParams['figure.dpi'] = dict_font[\"fig_dpi\"] * 1.2\n",
    "    plt.rcParams['figure.figsize'] = np.array(dict_font[\"fig_size\"]) * [0.8,0.7]\n",
    "    \n",
    "    plt.plot(silhouette_scores.keys(), silhouette_scores.values(), marker = \"x\", markersize = dict_font[\"font_txt\"] * 0.5)\n",
    "    \n",
    "    # coords = max(zip(silhouette_scores.values(), silhouette_scores.keys()))\n",
    "    coords = max(silhouette_scores, key = silhouette_scores.get), max(silhouette_scores.values())\n",
    "    plt.plot(coords[0], coords[1], \"or\", markersize = dict_font[\"font_xy\"] * 0.8, label = \"Optimal Number\")\n",
    "    \n",
    "    plt.legend(title = 'Nr. Cluster', loc = 'best', fontsize = dict_font[\"font_txt\"] * 0.8)\n",
    "    plt.xticks(k_to_test)\n",
    "    plt.title(\"Silhouette analysis for optimal k\", fontsize = dict_font[\"font_title\"])\n",
    "    plt.xlabel(\"k\", fontsize = dict_font[\"font_xy\"])\n",
    "    plt.ylabel(\"Silhouette Score\", fontsize = dict_font[\"font_xy\"])\n",
    "    plt.xticks(fontsize = dict_font[\"font_txt\"] * 0.9)\n",
    "    plt.yticks(fontsize = dict_font[\"font_txt\"] * 0.9)\n",
    "    \n",
    "    return plt.show(), silhouette_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cee9d",
   "metadata": {},
   "source": [
    "#### K-Means plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455b8ab",
   "metadata": {},
   "source": [
    "Plot of clusters choosen with silhouette method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475d7e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_plot(scaled_df, silhouette_scores, dict_font):\n",
    "    kmeans_model = KMeans(n_clusters = max(silhouette_scores, key = silhouette_scores.get) )\n",
    "    kmeans_model.fit(scaled_df)\n",
    "    centroids = kmeans_model.cluster_centers_\n",
    "\n",
    "    city_clust = scaled_df.copy()\n",
    "    city_clust[\"Cluster\"] = kmeans_model.labels_ # distinguish colors\n",
    "    city_clust[\"City\"] = new_df[\"City\"]\n",
    "\n",
    "    plt.rcParams['figure.dpi'] = dict_font[\"fig_dpi\"] * 1.2\n",
    "    plt.rcParams['figure.figsize'] = dict_font[\"fig_size\"]\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = np.array(dict_font[\"fig_size\"])*[1.1,1.1])\n",
    "\n",
    "    sns.scatterplot(x = \"TempCels\", y = \"Latitude\", data = city_clust, hue = \"Cluster\", palette = \"Accent\", ax = ax1, legend = False)\n",
    "    sns.scatterplot(x = \"TempCels\", y = \"RelHum\", data = city_clust, hue = \"Cluster\", palette = \"Accent\", ax = ax2, legend = False)\n",
    "    sns.scatterplot(x = \"SpecHum\", y = \"Latitude\", data = city_clust, hue = \"Cluster\", palette = \"Accent\", ax = ax3, legend = False)\n",
    "    sns.scatterplot(x = \"SpecHum\", y = \"TempCels\", data = city_clust, hue = \"Cluster\", palette = \"Accent\", ax = ax4, legend = False)\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38995f",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdab187",
   "metadata": {},
   "source": [
    "First, for a set of alpha the model is fitted; \n",
    "then by using the best alpha (i.e., the one which produces lowest MSE), the final model is printed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c12fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(X_train, X_test, y_train, y_test):\n",
    "    ridge = Ridge(fit_intercept = True)\n",
    "    coefs = []\n",
    "    mse_list = []\n",
    "\n",
    "    alphas = 10**np.linspace(start = 10, stop = -2, num = 250)*0.5\n",
    "\n",
    "    for a in alphas:\n",
    "        ridge.set_params(alpha = a)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        coefs.append(ridge.coef_)\n",
    "        mse_list.append(metrics.mean_squared_error(y_test, ridge.predict(X_test)))\n",
    "\n",
    "    alpha_best = alphas[np.argmin(mse_list)]\n",
    "    print(\"Penalties tested:\", len(alphas))\n",
    "    print(\"Numbers of predictors:\", np.shape(coefs)[1])\n",
    "    print(\"Best alpha: \", round(alpha_best, 4))\n",
    "    \n",
    "    ridge_best = Ridge(alpha = alpha_best, fit_intercept = True)\n",
    "    ridge_best.fit(X_train, y_train)\n",
    "    y_hat = ridge_best.predict(X_test)\n",
    "    print(\"Test MSE: \", round(metrics.mean_squared_error(y_test, y_hat), 3), sep = \"\")\n",
    "\n",
    "    print(\"Intercept\", \": \", \"\\u03B2\", 0, \" = \",  round(ridge_best.intercept_, 3), sep = \"\")\n",
    "    for i in range(len(ridge_best.feature_names_in_)):\n",
    "        print(ridge_best.feature_names_in_[i], \": \", \"\\u03B2\", i+1, \" = \" ,\n",
    "              round(ridge_best.coef_[i], 3), sep = \"\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0188e",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ed4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(X_train, X_test, y_train, y_test):\n",
    "    lasso = Lasso(max_iter = 10000, fit_intercept = True)\n",
    "    coefs = []\n",
    "    mse_list = []\n",
    "\n",
    "    alphas = 10**np.linspace(start = 10, stop = -2, num = 250)*0.5\n",
    "\n",
    "    for a in alphas:\n",
    "        lasso.set_params(alpha = a)\n",
    "        lasso.fit(X_train, y_train)\n",
    "        coefs.append(lasso.coef_)\n",
    "        mse_list.append(metrics.mean_squared_error(y_test, lasso.predict(X_test)))\n",
    "\n",
    "    alpha_best = alphas[np.argmin(mse_list)]\n",
    "    print(\"Penalties tested:\", np.shape(coefs)[0])\n",
    "    print(\"Numbers of predictors:\", np.shape(coefs)[1])\n",
    "    print(\"Best alpha: \", round(alpha_best, 4))\n",
    "    lasso_best = Lasso(alpha = alpha_best, fit_intercept=True)\n",
    "    lasso_best.fit(X_train, y_train)\n",
    "    y_hat = lasso_best.predict(X_test)\n",
    "    print(\"MSE: \", round(metrics.mean_squared_error(y_test, y_hat), 3), sep = \"\")\n",
    "    \n",
    "    print(\"Intercept\", \": \", \"\\u03B2\", 0,  \" = \", round(lasso_best.intercept_, 3), sep = \"\")\n",
    "    for i in range(len(lasso_best.feature_names_in_)):\n",
    "          print(lasso_best.feature_names_in_[i], \": \" ,\"\\u03B2\", i+1, \" = \", \n",
    "                round(lasso_best.coef_[i], 3), sep = \"\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f5509",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8306b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "    models_best = pd.DataFrame( columns = [\"RSS\", \"model\"] ) # empty\n",
    "\n",
    "    X_train[\"Const\"] = 1\n",
    "    X_test[\"Const\"] = 1\n",
    "\n",
    "    for i in range(1,len(X_train.columns) + 1): # + 1 to include the model with all vars as regressors\n",
    "        models_best.loc[i] = get_best(i, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    fs_coeff = pd.DataFrame({\n",
    "        \"Nr Coef\": [(i+1) for i in range(models_best.shape[0])],\n",
    "        \"RSS\": models_best[\"RSS\"] })\n",
    "    \n",
    "    #del X_train[\"Const\"]\n",
    "    #del X_test[\"Const\"]\n",
    "    \n",
    "    return fs_coeff, models_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598af453",
   "metadata": {},
   "source": [
    "In order to perform best subset selection it is required to identify the best model that contains a given number of predictors. We'll define a helper function to outputs the best set of variables for each model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(i, X_train, X_test, y_train, y_test):  \n",
    "    results = []\n",
    "    for var_subset in itertools.combinations(X_train.columns, i):\n",
    "        results.append(process_subset(var_subset, X_train, X_test, y_train, y_test)) \n",
    "                                        # returns dict with model and its RSS\n",
    "    \n",
    "    models = pd.DataFrame(results)\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac09bc5",
   "metadata": {},
   "source": [
    "This function fits a model for a certain subset of predictors. Instead of evaluating the MSE, the RSS is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42670f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subset(var_subset, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = sm.OLS(y_train, X_train[list(var_subset)], hasconst = False) #constant is included\n",
    "    regr = model.fit()\n",
    "    y_hat = regr.predict(X_test[list(var_subset)])\n",
    "    RSS = ((y_test - y_hat) ** 2).sum()\n",
    "    \n",
    "    return {\"model\" : regr, \"RSS\" : RSS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374e400",
   "metadata": {},
   "source": [
    "#### Plot for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3affca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fs(models_best, dict_font):\n",
    "    plt.rcParams['figure.dpi'] = dict_font[\"fig_dpi\"]\n",
    "    plt.rcParams['figure.figsize'] = dict_font[\"fig_size\"]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(models_best[\"RSS\"], marker = \"x\", markersize = 12)\n",
    "    plt.plot(models_best[\"RSS\"].argmin()+1, models_best[\"RSS\"].min(), \"or\", markersize = dict_font[\"font_xy\"] * 0.8,\n",
    "            label = \"Optimal Number\")\n",
    "    leg1 = plt.legend(title = 'Predictors', loc='best', fontsize = dict_font[\"font_txt\"] * 0.75)\n",
    "    leg1.set_title(title = 'Predictors', prop = {'size': dict_font[\"font_title\"] * 0.8})\n",
    "    plt.xlabel('Number of Predictors', fontsize = dict_font[\"font_xy\"])\n",
    "    plt.ylabel('RSS', fontsize = dict_font[\"font_xy\"])\n",
    "    plt.xticks(ticks = [(i+1) for i in range(models_best.shape[0])], fontsize = dict_font[\"font_xy\"], rotation=0)\n",
    "    plt.yticks(fontsize = dict_font[\"font_xy\"])\n",
    "\n",
    "    aic = models_best.apply(lambda row: row[1].aic, axis=1)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(aic, marker = \"x\", markersize = 12)\n",
    "    plt.plot(aic.argmin()+1, aic.min(), \"or\", markersize = dict_font[\"font_xy\"] * 0.8, label = \"Optimal Number\")\n",
    "    plt.legend(title = 'Predictors', loc='best', fontsize = dict_font[\"font_txt\"] * 0.8)\n",
    "    leg2 = plt.legend(title = 'Predictors', loc='best', fontsize = dict_font[\"font_txt\"] * 0.75)\n",
    "    leg2.set_title(title = 'Predictors', prop = {'size': dict_font[\"font_title\"] * 0.8})\n",
    "    plt.yticks(fontsize = dict_font[\"font_xy\"])\n",
    "    plt.xticks(ticks = [(i+1) for i in range(models_best.shape[0])], fontsize = dict_font[\"font_xy\"], rotation=0)\n",
    "\n",
    "    plt.xlabel('Number of Predictors', fontsize = dict_font[\"font_xy\"])\n",
    "    plt.ylabel('AIC', fontsize = dict_font[\"font_xy\"])\n",
    "    plt.tight_layout(pad = 3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
