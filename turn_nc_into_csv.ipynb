{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1acfe14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import netCDF4\n",
    "import glob\n",
    "\n",
    "RAW_PATH = '..'\n",
    "DATA_PATH = f'{RAW_PATH}/data'\n",
    "RESULTS_PATH = f'{RAW_PATH}/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a139d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "file_list = glob.glob(f'{DATA_PATH}/*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f5e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_name(file_name):\n",
    "    if '2020_' in file_name:\n",
    "        return file_name[:-3].split('2020_')[1]\n",
    "    else:\n",
    "        return 'Wrong Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f4f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_nc_into_csv(nc_data, city):\n",
    "    time = nc_data.variables['time']\n",
    "    t2m = nc_data.variables['t2m']\n",
    "    d2m = nc_data.variables['d2m']\n",
    "    sp = nc_data.variables['sp']\n",
    "    \n",
    "    dates = netCDF4.num2date(time[:], time.units, time.calendar)\n",
    "    data = pd.DataFrame({'date': dates[:], 't2m':t2m[:,0,0], 'd2m': d2m[:,0,0], 'sp': sp[:,0,0]})\n",
    "    data.to_csv(f'{RESULTS_PATH}/{city}.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0202ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_units_info():\n",
    "    nc_data = netCDF4.Dataset(file_list[0])\n",
    "    t2m = nc_data.variables['t2m']\n",
    "    d2m = nc_data.variables['d2m']\n",
    "    sp = nc_data.variables['sp']\n",
    "    \n",
    "    units_info = pd.DataFrame([['t2m', t2m.long_name, t2m.units], \n",
    "                               ['d2m', d2m.long_name, d2m.units], \n",
    "                               ['sp', sp.long_name, sp.units]])\n",
    "    units_info.columns = ['variable', 'long name', 'unit']\n",
    "    units_info.to_csv(f'{RESULTS_PATH}/units_info.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a846b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geo_info():\n",
    "    data = []\n",
    "    for file_name in file_list:\n",
    "        nc_data = netCDF4.Dataset(file_name)\n",
    "        lat = nc_data.variables['latitude']\n",
    "        lon = nc_data.variables['longitude']\n",
    "        if not ('Wrong Name' in city_name(file_name)):\n",
    "            data.append([city_name(file_name), lat[0], lon[0]])\n",
    "        else:\n",
    "            continue\n",
    "    geo_info = pd.DataFrame(data)\n",
    "    geo_info.columns = ['city', 'lat', 'lon']\n",
    "    geo_info.to_csv(f'{RESULTS_PATH}/geo_info.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90116969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data\\\\ERA5_2019-2020_Bangkok.nc',\n",
       " '../data\\\\ERA5_2019-2020_Bogota.nc',\n",
       " '../data\\\\ERA5_2019-2020_Cairo.nc',\n",
       " '../data\\\\ERA5_2019-2020_Daegu.nc',\n",
       " '../data\\\\ERA5_2019-2020_Heinsberg.nc',\n",
       " '../data\\\\ERA5_2019-2020_London.nc',\n",
       " '../data\\\\ERA5_2019-2020_Madrid.nc',\n",
       " '../data\\\\ERA5_2019-2020_Manilla.nc',\n",
       " '../data\\\\ERA5_2019-2020_Melbourne.nc',\n",
       " '../data\\\\ERA5_2019-2020_Milan.nc',\n",
       " '../data\\\\ERA5_2019-2020_Moscow.nc',\n",
       " '../data\\\\ERA5_2019-2020_Oslo.nc',\n",
       " '../data\\\\ERA5_2019-2020_Paris.nc',\n",
       " '../data\\\\ERA5_2019-2020_Qom.nc',\n",
       " '../data\\\\ERA5_2019-2020_SaoPaulo.nc',\n",
       " '../data\\\\ERA5_2019-2020_Seattle.nc',\n",
       " '../data\\\\ERA5_2019-2020_Solo.nc',\n",
       " '../data\\\\ERA5_2019-2020_Tokyo.nc',\n",
       " '../data\\\\ERA5_2019-2020_Toronto.nc',\n",
       " '../data\\\\ERA5_2019-2020_Wuhan.nc',\n",
       " '../data\\\\ERA5_2020-2021_Bangkok.nc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb921ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-dd84c8e7b157>:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dates = netCDF4.num2date(time[:], time.units, time.calendar)\n",
      "<ipython-input-4-dd84c8e7b157>:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  dates = netCDF4.num2date(time[:], time.units, time.calendar)\n",
      "<ipython-input-4-dd84c8e7b157>:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = pd.DataFrame({'date': dates[:], 't2m':t2m[:,0,0], 'd2m': d2m[:,0,0], 'sp': sp[:,0,0]})\n"
     ]
    }
   ],
   "source": [
    "for file_name in file_list:\n",
    "    if not ('Wrong Name' in city_name(file_name)):\n",
    "        turn_nc_into_csv(netCDF4.Dataset(file_name), city_name(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54291b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c9f0491c0df0>:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data.append([city_name(file_name), lat[0], lon[0]])\n"
     ]
    }
   ],
   "source": [
    "save_geo_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9cd414d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b46c76be9bfa>:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  units_info = pd.DataFrame([['t2m', t2m.long_name, t2m.units],\n",
      "<ipython-input-5-b46c76be9bfa>:8: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  ['d2m', d2m.long_name, d2m.units],\n",
      "<ipython-input-5-b46c76be9bfa>:9: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  ['sp', sp.long_name, sp.units]])\n"
     ]
    }
   ],
   "source": [
    "save_units_info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
